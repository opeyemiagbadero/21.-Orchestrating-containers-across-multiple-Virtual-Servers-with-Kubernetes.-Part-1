## Orchestrating containers across multiple Virtual Servers with Kubernetes. Part 1 ##

In this project, a Kubernetes cluster is manually setup from the scratch for a better understanding of each all components for spinning up a Kubernetes cluster

Confirm the installation of the AWS cli on your local machine and test your AWS CLI by running the command `aws ec2 describe-vpcs`

![1  confirm the installation of the AWS Cli and test AWS cli](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/4b2a2e2f-c58e-4578-ba08-4d08dc2f01d0)

![1  install AWS CLi](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/ccc95e37-674f-46b0-950c-e6d414938b0a)


![2  AWS Credentials and AWS CLI testrun](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/9794b60d-b351-4bae-9bac-bf20f1b1e5ec)

Install Kubectl on your local machine and confirm it has been installed. Use the following commands to get it done on a linux machine.

- Download the binary `wget https://storage.googleapis.com/kubernetes-release/release/v1.21.0/bin/linux/amd64/kubectl`
- Make it executable `chmod +x kubectl`
- Move to the Bin directory `sudo mv kubectl /usr/local/bin/`

Confirm the output of the installaton by running the command `kubectl version --client`

Install CFSSL and CFSSLJSON. cfssl is an open source tool by Cloudflare used to setup a Public Key Infrastructure (PKI Infrastructure) for generating, signing and bundling TLS certificates.

- Download the binary `wget -q --show-progress --https-only --timestamping \
  https://storage.googleapis.com/kubernetes-the-hard-way/cfssl/1.4.1/linux/cfssl \
  https://storage.googleapis.com/kubernetes-the-hard-way/cfssl/1.4.1/linux/cfssljson`
- make it executable `chmod +x cfssl cfssljson`
- move to the binary directory `sudo mv cfssl cfssljson /usr/local/bin/`


![3  Install CFSSL and CFSSLJSON and verify they have been installed](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/67849cbe-7add-47a5-a31a-d5b5d03d72d0)


# Step 1 Configuring the Network Infrastructure #

Create a directory named k8s-cluster-from-ground-up

Create a VPC and store the ID as a variable:

```VPC_ID=$(aws ec2 create-vpc \
--cidr-block 172.31.0.0/16 \
--output text --query 'Vpc.VpcId')
```

Tag the VPC so that it is named:
```NAME=k8s-cluster-from-ground-up

aws ec2 create-tags \
  --resources ${VPC_ID} \
  --tags Key=Name,Value=${NAME}
  ```


![4  K8s-cluster-from ground-up](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/a6a92ed8-1712-41c8-a8ee-e3d9c8e9008e)


Enable DNS support for your VPC:
```aws ec2 modify-vpc-attribute \
--vpc-id ${VPC_ID} \
--enable-dns-support '{"Value": true}
```

Enable DNS support for hostnames:

```aws ec2 modify-vpc-attribute \
--vpc-id ${VPC_ID} \
--enable-dns-hostnames '{"Value": true}'
```

![5 confirm that the dns hostname and dns resolution has been enabled](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/beb8645a-58f6-43d4-a989-61466d3bf56e)


Set the required region
`AWS_REGION=eu-central-1`

Configure DHCP Options Set

```DHCP_OPTION_SET_ID=$(aws ec2 create-dhcp-options \
  --dhcp-configuration \
    "Key=domain-name,Values=$AWS_REGION.compute.internal" \
    "Key=domain-name-servers,Values=AmazonProvidedDNS" \
  --output text --query 'DhcpOptions.DhcpOptionsId')
  ```
  
  Tag the DHCP Option set:
```aws ec2 create-tags \
  --resources ${DHCP_OPTION_SET_ID} \
  --tags Key=Name,Value=${NAME}
  ```
   
![6  DHCP Option-sets](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/c6fd075d-6be4-442f-bc8e-b608a983a15f)

Associate the DHCP Option set with the VPC:
  
![7 DHCP optionset showing reflecting under VPC](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/f014f2f0-4ce2-4b76-aefe-70a2e384ebc4)


Create and tag the subnet
```SUBNET_ID=$(aws ec2 create-subnet \
  --vpc-id ${VPC_ID} \
  --cidr-block 172.31.0.0/24 \
  --output text --query 'Subnet.SubnetId')
  ```
  
  ```aws ec2 create-tags \
  --resources ${SUBNET_ID} \
  --tags Key=Name,Value=${NAME}
  ```
    
  ![8  subnets](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/cbe62beb-59fb-4c7e-a936-c24a488b6f1c)

Create the Internet Gateway and attach it to the VPC:

```INTERNET_GATEWAY_ID=$(aws ec2 create-internet-gateway \
  --output text --query 'InternetGateway.InternetGatewayId')
aws ec2 create-tags \
  --resources ${INTERNET_GATEWAY_ID} \
  --tags Key=Name,Value=${NAME}
  ```
  
```aws ec2 attach-internet-gateway \
  --internet-gateway-id ${INTERNET_GATEWAY_ID} \
  --vpc-id ${VPC_ID}
  ```
  
  ![9 Internet gateway](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/951ec14b-b618-4311-a8fa-5eca90519a95)


Route tables
Create route tables, associate the route table to subnet, and create a route to allow external traffic to the Internet through the Internet Gateway:

```
ROUTE_TABLE_ID=$(aws ec2 create-route-table \
  --vpc-id ${VPC_ID} \
  --output text --query 'RouteTable.RouteTableId')
aws ec2 create-tags \
  --resources ${ROUTE_TABLE_ID} \
  --tags Key=Name,Value=${NAME}
aws ec2 associate-route-table \
  --route-table-id ${ROUTE_TABLE_ID} \
  --subnet-id ${SUBNET_ID}
aws ec2 create-route \
  --route-table-id ${ROUTE_TABLE_ID} \
  --destination-cidr-block 0.0.0.0/0 \
  --gateway-id ${INTERNET_GATEWAY_ID}
  ```
   
  ![10 route tables](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/6de50056-c185-4987-b15d-a10a9377ba13)

 
 Configure the Security Group
  
  ```
  # Create the security group and store its ID in a variable
SECURITY_GROUP_ID=$(aws ec2 create-security-group \
  --group-name ${NAME} \
  --description "Kubernetes cluster security group" \
  --vpc-id ${VPC_ID} \
  --output text --query 'GroupId')

# Create the NAME tag for the security group
aws ec2 create-tags \
  --resources ${SECURITY_GROUP_ID} \
  --tags Key=Name,Value=${NAME}

# Create Inbound traffic for all communication within the subnet to connect on ports used by the master node(s)
aws ec2 authorize-security-group-ingress \
    --group-id ${SECURITY_GROUP_ID} \
    --ip-permissions IpProtocol=tcp,FromPort=2379,ToPort=2380,IpRanges='[{CidrIp=172.31.0.0/24}]'

# # Create Inbound traffic for all communication within the subnet to connect on ports used by the worker nodes
aws ec2 authorize-security-group-ingress \
    --group-id ${SECURITY_GROUP_ID} \
    --ip-permissions IpProtocol=tcp,FromPort=30000,ToPort=32767,IpRanges='[{CidrIp=172.31.0.0/24}]'

# Create inbound traffic to allow connections to the Kubernetes API Server listening on port 6443
aws ec2 authorize-security-group-ingress \
  --group-id ${SECURITY_GROUP_ID} \
  --protocol tcp \
  --port 6443 \
  --cidr 0.0.0.0/0

# Create Inbound traffic for SSH from anywhere (Do not do this in production. Limit access ONLY to IPs or CIDR that MUST connect)
aws ec2 authorize-security-group-ingress \
  --group-id ${SECURITY_GROUP_ID} \
  --protocol tcp \
  --port 22 \
  --cidr 0.0.0.0/0

# Create ICMP ingress for all types
aws ec2 authorize-security-group-ingress \
  --group-id ${SECURITY_GROUP_ID} \
  --protocol icmp \
  --port -1 \
  --cidr 0.0.0.0/0
  ```

![11  Security groups](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/f9121304-a8cb-4851-8c98-bd3f3f4a5380)


Create a network Load balancer,

```
LOAD_BALANCER_ARN=$(aws elbv2 create-load-balancer \
--name ${NAME} \
--subnets ${SUBNET_ID} \
--scheme internet-facing \
--type network \
--output text --query 'LoadBalancers[].LoadBalancerArn')
```

![12 load balancers](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/61b934e8-d402-40b8-a497-af1501ef7278)


Create a target group: (For now it will be unhealthy because there are no real targets yet.)

```
TARGET_GROUP_ARN=$(aws elbv2 create-target-group \
  --name ${NAME} \
  --protocol TCP \
  --port 6443 \
  --vpc-id ${VPC_ID} \
  --target-type ip \
  --output text --query 'TargetGroups[].TargetGroupArn')
  ```
  
  
![13 target group](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/5ed08813-7b91-4841-b534-1a6bfd45279d)


Register targets: (Just like above, no real targets. You will just put the IP addresses so that, when the nodes become available, they will be used as targets.)

```
aws elbv2 register-targets \
  --target-group-arn ${TARGET_GROUP_ARN} \
  --targets Id=172.31.0.1{0,1,2}
  ```
  
![14 target group2](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/32cc3e80-38c6-4320-a3a1-6605b85663a7)



Create a listener to listen for requests and forward to the target nodes on TCP port 6443

```
aws elbv2 create-listener \
--load-balancer-arn ${LOAD_BALANCER_ARN} \
--protocol TCP \
--port 6443 \
--default-actions Type=forward,TargetGroupArn=${TARGET_GROUP_ARN} \
--output text --query 'Listeners[].ListenerArn'
```

![15  LIsteners](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/ccf36c51-389b-4dc2-9ace-a11c8d3114e4)


Get the Kubernetes Public address
```
KUBERNETES_PUBLIC_ADDRESS=$(aws elbv2 describe-load-balancers \
--load-balancer-arns ${LOAD_BALANCER_ARN} \
--output text --query 'LoadBalancers[].DNSName')
```


Get an image to create EC2 instances:

```
IMAGE_ID=$(aws ec2 describe-images --owners 099720109477 \
  --filters \
  'Name=root-device-type,Values=ebs' \
  'Name=architecture,Values=x86_64' \
  'Name=name,Values=ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-*' \
  | jq -r '.Images|sort_by(.Name)[-1]|.ImageId')
  ```
  
  
  ![17  AMI used to build EC2 instances](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/ee0dd660-2e29-4356-b21c-829edb226fc1)

 
  Create SSH Key-Pair
  
  ```
  mkdir -p ssh

aws ec2 create-key-pair \
  --key-name ${NAME} \
  --output text --query 'KeyMaterial' \
  > ssh/${NAME}.id_rsa
chmod 600 ssh/${NAME}.id_rsa
```

  ![16 keypairs](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/c1c74af1-3075-40bd-9e61-4b00b7d4d016)


Create 3 Master nodes: Note â€“ Using t2.micro instead of t2.small as t2.micro is covered by AWS free tier


```
for i in 0 1 2; do
  instance_id=$(aws ec2 run-instances \
    --associate-public-ip-address \
    --image-id ${IMAGE_ID} \
    --count 1 \
    --key-name ${NAME} \
    --security-group-ids ${SECURITY_GROUP_ID} \
    --instance-type t2.micro \
    --private-ip-address 172.31.0.1${i} \
    --user-data "name=master-${i}" \
    --subnet-id ${SUBNET_ID} \
    --output text --query 'Instances[].InstanceId')
  aws ec2 modify-instance-attribute \
    --instance-id ${instance_id} \
    --no-source-dest-check
  aws ec2 create-tags \
    --resources ${instance_id} \
    --tags "Key=Name,Value=${NAME}-master-${i}"
done
```


Create 3 worker nodes:

```
for i in 0 1 2; do
  instance_id=$(aws ec2 run-instances \
    --associate-public-ip-address \
    --image-id ${IMAGE_ID} \
    --count 1 \
    --key-name ${NAME} \
    --security-group-ids ${SECURITY_GROUP_ID} \
    --instance-type t2.micro \
    --private-ip-address 172.31.0.2${i} \
    --user-data "name=worker-${i}|pod-cidr=172.20.${i}.0/24" \
    --subnet-id ${SUBNET_ID} \
    --output text --query 'Instances[].InstanceId')
  aws ec2 modify-instance-attribute \
    --instance-id ${instance_id} \
    --no-source-dest-check
  aws ec2 create-tags \
    --resources ${instance_id} \
    --tags "Key=Name,Value=${NAME}-worker-${i}"
done
```


![18 EC2 Instances for Controle Plane (Master Nodes) and worker nodes](https://github.com/opeyemiagbadero/21.-Orchestrating-containers-across-multiple-Virtual-Servers-with-Kubernetes.-Part-1/assets/79456052/8b8b9ce6-e42b-40f3-a463-24fe0b9dacc3)


























































































































